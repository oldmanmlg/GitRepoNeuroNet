{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.2191 - acc: 0.9350\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0967 - acc: 0.9706\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 12s 206us/sample - loss: 0.0707 - acc: 0.9778\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0538 - acc: 0.9828\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 0.0431 - acc: 0.9856\n",
      "10000/10000 [==============================] - 1s 94us/sample - loss: 0.0661 - acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0660958974437788, 0.9811]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train1, x_test1 = x_train, x_test\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainn = tf.keras.utils.normalize(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.12170641\n",
      "  0.34193707 0.63461202 0.48103011 0.34193707 0.34193707 0.01738663\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.16365522 0.38451033\n",
      "  0.40357696 0.40357696 0.40357696 0.40357696 0.40357696 0.10486645\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.02718946 0.35044198\n",
      "  0.38367354 0.38367354 0.38367354 0.38367354 0.38367354 0.35950513\n",
      "  0.1057368  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16475321\n",
      "  0.38653638 0.40237804 0.35485307 0.40237804 0.40237804 0.40237804\n",
      "  0.22336734 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35182465 0.43170754 0.35692355 0.43170754 0.43170754 0.43170754\n",
      "  0.05778762 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15105446 0.37044309 0.45675992 0.45675992 0.45675992 0.45675992\n",
      "  0.07372896 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04644278 0.4044392  0.49151942 0.49151942 0.49151942\n",
      "  0.3309048  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16693707 0.25132285 0.46412175 0.46595623 0.46595623 0.46595623\n",
      "  0.20546101 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06074343 0.32497736\n",
      "  0.37964645 0.3857208  0.3857208  0.3857208  0.3857208  0.3857208\n",
      "  0.05163192 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11740585 0.35801538\n",
      "  0.36816157 0.36816157 0.36816157 0.36816157 0.36816157 0.36816157\n",
      "  0.21162043 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16884417\n",
      "  0.37759696 0.38987654 0.38987654 0.38987654 0.38987654 0.38987654\n",
      "  0.26247594 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17150284 0.20909251 0.20909251 0.21848993 0.56384497 0.59673593\n",
      "  0.40173954 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00277539 0.35525005 0.70494932\n",
      "  0.60781063 0.08603712 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01670169 0.60603268 0.60603268\n",
      "  0.51059446 0.06680675 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.34336008 0.6319816  0.6319816\n",
      "  0.28862152 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.03977342 0.3705208  0.18840041 0.         0.         0.\n",
      "  0.         0.         0.05233345 0.50240108 0.53170781 0.53170781\n",
      "  0.07117349 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.27950517 0.43289215 0.36642446 0.10737089 0.06135479 0.\n",
      "  0.08691929 0.15168268 0.35108576 0.43289215 0.43289215 0.23689767\n",
      "  0.0136344  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07690172 0.26578314 0.34268486 0.34268486 0.29951197 0.24284754\n",
      "  0.32514587 0.34268486 0.34268486 0.34133571 0.28736959 0.01484068\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20347268 0.15260451 0.36915758 0.36915758 0.36915758\n",
      "  0.36915758 0.36915758 0.36915758 0.34299681 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.01419131 0.23719763 0.23719763 0.33450948\n",
      "  0.51494186 0.51494186 0.48453191 0.10136651 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_trainn[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 9.8336 - acc: 0.9733\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: 3.9938 - acc: 0.9801\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 3.2953 - acc: 0.9800\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 2.8999 - acc: 0.9811\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 3.0007 - acc: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f6d529208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train1, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 140us/sample - loss: 7.0534 - acc: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.053416338121238, 0.9739]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.1545 - acc: 0.9666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15447673875689508, 0.9666]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  61   3  42 118 193 118 118\n",
      "   61   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14 179 245 236 242 254 254 254 254\n",
      "  245 235  84   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 151 254 254 254 213 192 178 178 180\n",
      "  254 254 241  46   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  43 235 254 226  64  28  12   0   0   2\n",
      "  128 252 255 173  17   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  56 254 253 107   0   0   0   0   0   0\n",
      "    0 134 250 254  75   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  63 254 158   0   0   0   0   0   0   0\n",
      "    0   0 221 254 157   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 194 254 103   0   0   0   0   0   0   0\n",
      "    0   0 150 254 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  34 220 239  58   0   0   0   0   0   0   0\n",
      "    0   0  84 254 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 126 254 171   0   0   0   0   0   0   0   0\n",
      "    0   0  84 254 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 214 239  60   0   0   0   0   0   0   0   0\n",
      "    0   0  84 254 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 214 199   0   0   0   0   0   0   0   0   0\n",
      "    0   0  84 254 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  11 219 199   0   0   0   0   0   0   0   0   0\n",
      "    0   0  84 254 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  98 254 199   0   0   0   0   0   0   0   0   0\n",
      "    0   0 162 254 209   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  98 254 199   0   0   0   0   0   0   0   0   0\n",
      "    0  51 238 254  75   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  98 254 199   0   0   0   0   0   0   0   0   0\n",
      "   51 165 254 195   4   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  66 241 199   0   0   0   0   0   0   0   0   3\n",
      "  167 254 227  55   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 214 213  20   0   0   0   0   0  46 152 202\n",
      "  254 254  63   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 214 254 204 180 180 180 180 180 235 254 254\n",
      "  234 156  10   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  81 205 254 254 254 254 254 254 254 252 234\n",
      "  120   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  26 210 254 254 254 254 254 153 104   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test1[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(num):\n",
    "    label = y_test[num]\n",
    "    image = x_test[num]\n",
    "    plt.title('Example: {}  Label: {}'.format(num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.20),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss = {}, accuracy = {}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train)\n",
    "print(\"Loss = {}, accuracy = {}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[0:1,:,:])\n",
    "print(predictions)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
